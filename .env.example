# Hugging Face token with access to the model
HF_TOKEN=YOUR_HF_TOKEN_HERE

# Model to serve
MODEL_HANDLE=openai/gpt-oss-120b

# Where to persist HF downloads on the host
HF_CACHE_DIR=/opt/hf-cache

# API bind settings
HOST=0.0.0.0
PORT=8355

# Container image (DGX Spark-specific TRT-LLM build)
TRTLLM_IMAGE=nvcr.io/nvidia/tensorrt-llm/release:spark-single-gpu-dev

# Optional: if your network blocks outbound, set proxy vars here
# HTTPS_PROXY=
# HTTP_PROXY=
# NO_PROXY=localhost,127.0.0.1
